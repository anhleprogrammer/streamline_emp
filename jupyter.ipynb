{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read employee information file\n",
    "empinfo_df = pd.read_excel(\"employee_information.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  employee_id employee_last_name employee_first_name employee_country  \\\n",
      "0      A2R5H9             Hunman                 Jax               BE   \n",
      "1      H8K0L6               Siff                Tara               GB   \n",
      "2      G4R7V0              Sagal               Gemma               US   \n",
      "3      M1Z7U9             Coates                 Tig               FR   \n",
      "\n",
      "  employee_city      employee_street  employee_street_number  \n",
      "0        Leuven          Grote Markt                       9  \n",
      "1        London         Baker Street                     221  \n",
      "2      New-York         Perry Street                      66  \n",
      "3         Paris  Rue de l'UniversitÃ©                       7  \n"
     ]
    }
   ],
   "source": [
    "#Get 1st sheet to a separated dataframe\n",
    "print(empinfo_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A2R5H9  Hunman    Jax       Opie Hurst   +32-456-5556-84  Brother\n",
      "0  H8K0L6    Siff   Tara  Wendy de Matteo  +44-020-5554-333   Sister\n",
      "1  G4R7V0   Sagal  Gemma     John Newmark    +1-202-555-194  Husband\n",
      "2  M1Z7U9  Coates    Tig      Venus Noone   +1-202-555-0130     Wife\n"
     ]
    }
   ],
   "source": [
    "#Get 2nd sheet to a separated dataframe\n",
    "emergency_contacts_df = pd.read_excel(\"employee_information.xlsx\", sheet_name=1)\n",
    "print(emergency_contacts_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  employee_id last_name first_name emergency_contact emergency_contact_number  \\\n",
      "0      H8K0L6      Siff       Tara   Wendy de Matteo         +44-020-5554-333   \n",
      "1      G4R7V0     Sagal      Gemma      John Newmark           +1-202-555-194   \n",
      "2      M1Z7U9    Coates        Tig       Venus Noone          +1-202-555-0130   \n",
      "\n",
      "  relationship  \n",
      "0       Sister  \n",
      "1      Husband  \n",
      "2         Wife  \n"
     ]
    }
   ],
   "source": [
    "#Declare headers for second sheet\n",
    "emergency_contacts_header = [\"employee_id\", \"last_name\", \"first_name\",\n",
    "                             \"emergency_contact\", \"emergency_contact_number\" , \"relationship\"]\n",
    "#Rename the columns\n",
    "emergency_contacts_df.columns = emergency_contacts_header\n",
    "print(emergency_contacts_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read address file\n",
    "address_df = pd.read_csv(\"office_addresses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          office office_country    office_city   office_street  \\\n",
      "0  Leuven Office             BE         Leuven  Martelarenlaan   \n",
      "1     ESB Office             US  New York City    Fifth Avenue   \n",
      "2  WeWork Office             GB         London      Old Street   \n",
      "\n",
      "   office_street_number  \n",
      "0                    38  \n",
      "1                   350  \n",
      "2                   207  \n"
     ]
    }
   ],
   "source": [
    "#Print first rows of address information\n",
    "print(address_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          title monthly_salary               team\n",
      "employee_id                                                      \n",
      "A2R5H9                      CEO          $4500         Leadership\n",
      "G4R7V0       Business Developer          $3000              Sales\n",
      "H8K0L6                      CFO          $4500         Leadership\n",
      "M1Z7U9           Office Manager          $2000  People Operations\n"
     ]
    }
   ],
   "source": [
    "#Load JSON file\n",
    "employee_roles_df = pd.read_json(\"employee_roles.json\")\n",
    "employee_roles_df = employee_roles_df.reindex(sorted(employee_roles_df.columns), axis=1)\n",
    "#Rotate the DF, add column ID to the DF\n",
    "employee_roles_df = employee_roles_df.transpose()\n",
    "employee_roles_df = employee_roles_df.reset_index()\n",
    "employee_roles_df = employee_roles_df.rename(columns={'index' : 'employee_id'})\n",
    "employee_roles_df = employee_roles_df.set_index('employee_id')\n",
    "print(employee_roles_df )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'employee_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Merge address with emergency contact\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m merged_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmerge(address_df, emergency_contacts_df, on\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39memployee_id\u001b[39;49m\u001b[39m'\u001b[39;49m, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      3\u001b[0m \u001b[39m#Merge with employee roles\u001b[39;00m\n\u001b[1;32m      4\u001b[0m merged_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(merged_df, employee_roles_df, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39memployee_id\u001b[39m\u001b[39m'\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Projects/streamline_employee/venv/lib/python3.11/site-packages/pandas/core/reshape/merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m--> 110\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    111\u001b[0m         left,\n\u001b[1;32m    112\u001b[0m         right,\n\u001b[1;32m    113\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m    114\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m    115\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[1;32m    116\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[1;32m    117\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[1;32m    118\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[1;32m    119\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    120\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[1;32m    121\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[1;32m    122\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result(copy\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/Projects/streamline_employee/venv/lib/python3.11/site-packages/pandas/core/reshape/merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cross \u001b[39m=\u001b[39m cross_col\n\u001b[1;32m    698\u001b[0m \u001b[39m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    699\u001b[0m (\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_join_keys,\n\u001b[1;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys,\n\u001b[1;32m    702\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoin_names,\n\u001b[0;32m--> 703\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_merge_keys()\n\u001b[1;32m    705\u001b[0m \u001b[39m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[39m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m~/Projects/streamline_employee/venv/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1179\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[39mif\u001b[39;00m lk \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1176\u001b[0m     \u001b[39m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m     \u001b[39m#  the latter of which will raise\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m     lk \u001b[39m=\u001b[39m cast(Hashable, lk)\n\u001b[0;32m-> 1179\u001b[0m     left_keys\u001b[39m.\u001b[39mappend(left\u001b[39m.\u001b[39;49m_get_label_or_level_values(lk))\n\u001b[1;32m   1180\u001b[0m     join_names\u001b[39m.\u001b[39mappend(lk)\n\u001b[1;32m   1181\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1182\u001b[0m     \u001b[39m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/streamline_employee/venv/lib/python3.11/site-packages/pandas/core/generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     values \u001b[39m=\u001b[39m (\n\u001b[1;32m   1845\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\n\u001b[1;32m   1846\u001b[0m         \u001b[39m.\u001b[39mget_level_values(key)  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m         \u001b[39m.\u001b[39m_values\n\u001b[1;32m   1848\u001b[0m     )\n\u001b[1;32m   1849\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1850\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1852\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1853\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'employee_id'"
     ]
    }
   ],
   "source": [
    "#Merge address with emergency contact\n",
    "merged_df = pd.merge(address_df, emergency_contacts_df, on='employee_id', copy=False)\n",
    "#Merge with employee roles\n",
    "merged_df = pd.merge(merged_df, employee_roles_df, how='left', on='employee_id', copy=False)\n",
    "#Merge df employee with office address\n",
    "merged_df = pd.merge(merged_df, address_df, how='left', left_on='employee_country', right_on='office_country' , copy=False)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(merged_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "841f9b51acb6d7e400aae8d9e3f1fe1061a1a08f7b194e0c8dd13ca5ce068e04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
